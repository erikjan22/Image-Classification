{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DigitClassifierDemo notebook illustrates how the image processing process works and features a training session where four parameters (average area, average perimeter, avergage aspect ratio and average convex hull area to real area ratio) were found. These will be used in the following notebook, where I attempt to classify the images of the MNIST test training test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import loadlocal_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import statistics \n",
    "from timeit import default_timer as timer\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the MNIST test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 10000 images in the test data set.\n"
     ]
    }
   ],
   "source": [
    "directory = '/home/erik/Documents/Image-Classification/'\n",
    "\n",
    "X, y = loadlocal_mnist(\n",
    "        images_path= directory + 't10k-images.idx3-ubyte', \n",
    "        labels_path= directory + 't10k-labels.idx1-ubyte')\n",
    "\n",
    "numberImages = len(y)\n",
    "print('There are a total of %s images in the test data set.' %(numberImages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If visual inspection for one of the raw images is needed, this can be done here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of image: 0, Label of image: 7\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "myimage = X[index].reshape((28,28))\n",
    "plt.imshow(myimage,'gray')\n",
    "plt.title('Display of an image from the training data set')\n",
    "plt.show() \n",
    "print('Index of image: %s, Label of image: %s' %(index, y[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before an attempt is made to classify the images from the MNIST test data set, a random classification in made. This entails that each of the images is classified using a random label from the list of possible digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000, Number of errors: 9005, Accuracy: 0.0995\n",
      "Time it took for classification: 0.06 seconds\n"
     ]
    }
   ],
   "source": [
    "ErrorCount = 0\n",
    "resizing = 5\n",
    "numberSamples = numberImages\n",
    "\n",
    "startTime = timer()\n",
    "\n",
    "for index in range(0, numberSamples):\n",
    "    Guess = random.randint(0,9)\n",
    "    ActualLabel = y[index]\n",
    "    if ActualLabel != Guess:\n",
    "        ErrorCount += 1\n",
    "\n",
    "endTime = timer()\n",
    "    \n",
    "accuracy = (numberSamples-ErrorCount)/ numberSamples\n",
    "print('Number of samples: %s, Number of errors: %s, Accuracy: %s' %(numberSamples, ErrorCount, accuracy))\n",
    "\n",
    "print('Time it took for classification: %.2f seconds' %(endTime - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification of all the images in the data set (10000 samples), the random classifier made 9005 errors, meaning it has an accuracy of about 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Using the numberSamples variable the user can specify how many of the images from the test dataset they want to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four perimeters which will be used during the classification of some of the digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieved from the Demo:\n",
    "\n",
    "Digits = [2,3,4,5,7]\n",
    "Areas = [3787.8, 3874.4, 3324.0, 3465.5, 3220.3]\n",
    "Perimeters = [450.8, 501.2, 435.5, 471.8, 411.8]\n",
    "AspectRatios = [1.0413, 1.1720, 1.2360, 1.1121, 1.2691]\n",
    "ConvexHullRatios = [0.5960, 0.5882, 0.6052, 0.6030, 0.5977]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000, Number of errors: 7182, Accuracy: 0.2818\n",
      "Time it took for classification: 12.47 seconds\n"
     ]
    }
   ],
   "source": [
    "ErrorCount = 0\n",
    "resizing = 5\n",
    "numberSamples = numberImages\n",
    "\n",
    "startTime = timer()\n",
    "\n",
    "for index in range(0, numberSamples):\n",
    "    # Gathering info abou the image:\n",
    "    Image0 = X[index]\n",
    "    Image = cv2.resize(Image0.reshape((28,28)),None, fx = resizing, fy = resizing, interpolation = cv2.INTER_LINEAR)\n",
    "    maxycoord = resizing * 28\n",
    "    tvalue = statistics.mean(Image0)\n",
    "    maxvalue = max(Image0)\n",
    "    ret,BinIm = cv2.threshold(Image,tvalue,maxvalue,cv2.THRESH_BINARY)\n",
    "    edged=cv2.Canny(BinIm, 10, 200)\n",
    "    (contours, _)=cv2.findContours(BinIm,cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    # Ensuring that a contour is not being build around a spot of noise:\n",
    "    if len(contours) > 1 and cv2.contourArea(contours[0]) < cv2.contourArea(contours[1]):\n",
    "        contours = contours[1:]\n",
    "    \n",
    "    if len(contours) > 2:\n",
    "        # Only for digit 8\n",
    "        Guess = 8\n",
    "        \n",
    "    elif len(contours) == 2:\n",
    "        # For digits 0, 6 and 9\n",
    "        innerArea = cv2.contourArea(contours[0])\n",
    "        totalArea = cv2.contourArea(contours[1])\n",
    "        realArea = totalArea - innerArea\n",
    "        if innerArea/realArea > 0.25:\n",
    "            # Only for digit 0\n",
    "            Guess = 0\n",
    "        else:\n",
    "            moments = cv2.moments(contours[0])\n",
    "            ycentroid = moments['m01']/moments['m00']\n",
    "            maxycoord = resizing * 28\n",
    "            if ycentroid/maxycoord < 0.5:\n",
    "                # Only for digit 9\n",
    "                Guess = 9\n",
    "            else:\n",
    "                # Only for digit 6\n",
    "                Guess = 6\n",
    "    else:\n",
    "        # For digits 1, 2, 3, 4, 5, 7\n",
    "        (startingx, startingy, width, height) = cv2.boundingRect(contours[0])\n",
    "        aspect_ratio = height / width\n",
    "        if aspect_ratio > 2.5:\n",
    "            # Only for digit 1\n",
    "            Guess = 1\n",
    "        else:\n",
    "            # For digits 2, 3, 4, 5, 7\n",
    "            DigitArea = cv2.contourArea(contours[0])\n",
    "            DigitPerimeter = cv2.arcLength(contours[0], True)\n",
    "            (startingx, startingy, width, height) = cv2.boundingRect(contours[0])\n",
    "            DigitAspectRatio = height / width\n",
    "            hull = cv2.convexHull(contours[0])\n",
    "            hullArea = cv2.contourArea(hull)\n",
    "            DigitConvexHullRatio = DigitArea/hullArea\n",
    "            \n",
    "            scores = len(Digits) * [None]\n",
    "            for currentIndex in range(0, len(Digits)):\n",
    "                error_area = ((Areas[currentIndex] - DigitArea)/Areas[currentIndex])**2\n",
    "                error_per = ((Perimeters[currentIndex] - DigitPerimeter)/Perimeters[currentIndex])**2\n",
    "                error_aspect = ((AspectRatios[currentIndex] - DigitAspectRatio)/AspectRatios[currentIndex])**2\n",
    "                error_aspect = ((ConvexHullRatios[currentIndex] - DigitConvexHullRatio)/ConvexHullRatios[currentIndex])**2\n",
    "                scores[currentIndex] = error_area+error_per+error_aspect\n",
    "                       \n",
    "            Guess = Digits[scores.index(min(scores))] \n",
    "            \n",
    "    ActualLabel = y[index]\n",
    "    if ActualLabel != Guess:\n",
    "        ErrorCount += 1\n",
    "    #print('Index: %3s, Actual label: %s, Guess: %s' %(index, ActualLabel, Guess))\n",
    "\n",
    "endTime = timer()\n",
    "    \n",
    "accuracy = (numberSamples-ErrorCount)/ numberSamples\n",
    "print('Number of samples: %s, Number of errors: %s, Accuracy: %s' %(numberSamples, ErrorCount, accuracy))\n",
    "\n",
    "print('Time it took for classification: %.2f seconds' %(endTime - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification of all the images in the data set (10000 samples), the traditional classifier made 7182 errors, meaning it has an accuracy of about 28%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
